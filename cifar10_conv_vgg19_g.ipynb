{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o864MAI5ncPH"
      },
      "source": [
        "# Instalar Julia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4voqAvCnWlU"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "set -e\n",
        "\n",
        "#---------------------------------------------------#\n",
        "JULIA_VERSION=\"1.9.1\" # any version ≥ 0.7.0\n",
        "JULIA_PACKAGES=\"IJulia BenchmarkTools LinearAlgebra Statistics Flux MLDatasets BetaML Printf BSON\"\n",
        "JULIA_PACKAGES_IF_GPU=\"CUDA\" # or CuArrays for older Julia versions\n",
        "JULIA_NUM_THREADS=2\n",
        "#---------------------------------------------------#\n",
        "\n",
        "if [ -z `which julia` ]; then\n",
        "  # Install Julia\n",
        "  JULIA_VER=`cut -d '.' -f -2 <<< \"$JULIA_VERSION\"`\n",
        "  echo \"Installing Julia $JULIA_VERSION on the current Colab Runtime...\"\n",
        "  BASE_URL=\"https://julialang-s3.julialang.org/bin/linux/x64\"\n",
        "  URL=\"$BASE_URL/$JULIA_VER/julia-$JULIA_VERSION-linux-x86_64.tar.gz\"\n",
        "  wget -nv $URL -O /tmp/julia.tar.gz # -nv means \"not verbose\"\n",
        "  tar -x -f /tmp/julia.tar.gz -C /usr/local --strip-components 1\n",
        "  rm /tmp/julia.tar.gz\n",
        "\n",
        "  # Install Packages\n",
        "  nvidia-smi -L &> /dev/null && export GPU=1 || export GPU=0\n",
        "  if [ $GPU -eq 1 ]; then\n",
        "    JULIA_PACKAGES=\"$JULIA_PACKAGES $JULIA_PACKAGES_IF_GPU\"\n",
        "  fi\n",
        "  for PKG in `echo $JULIA_PACKAGES`; do\n",
        "    echo \"Installing Julia package $PKG...\"\n",
        "    julia -e 'using Pkg; pkg\"add '$PKG'; precompile;\"' &> /dev/null\n",
        "  done\n",
        "\n",
        "  # Install kernel and rename it to \"julia\"\n",
        "  echo \"Installing IJulia kernel...\"\n",
        "  julia -e 'using IJulia; IJulia.installkernel(\"julia\", env=Dict(\n",
        "      \"JULIA_NUM_THREADS\"=>\"'\"$JULIA_NUM_THREADS\"'\"))'\n",
        "  KERNEL_DIR=`julia -e \"using IJulia; print(IJulia.kerneldir())\"`\n",
        "  KERNEL_NAME=`ls -d \"$KERNEL_DIR\"/julia*`\n",
        "  mv -f $KERNEL_NAME \"$KERNEL_DIR\"/julia\n",
        "\n",
        "  echo ''\n",
        "  echo \"Successfully installed `julia -v`!\"\n",
        "  echo \"Please reload this page (press Ctrl+R, ⌘+R, or the F5 key) then\"\n",
        "  echo \"jump to the 'Checking the Installation' section.\"\n",
        "fi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLfFMVaDnhE6"
      },
      "source": [
        "# Codigo"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "using LinearAlgebra, Statistics, Flux, MLDatasets, CUDA\n",
        "using BetaML: ConfusionMatrix, fit!, info\n",
        "using Printf, BSON\n",
        "\n",
        "\n",
        "# Treino\n",
        "class_names = MLDatasets.CIFAR10().metadata[\"class_names\"]\n",
        "x_treino, y_treino = MLDatasets.CIFAR10(Float32, split=:train)[:] |> gpu\n",
        "#x_treino = permutedims(x_treino, (2, 1, 3, 4));\n",
        "#x_treino = convert(CuArray{Float32,4}, x_treino);\n",
        "#x_treino = reshape(x_treino, (32, 32, 3, 50000));\n",
        "média_x_treino = mean(x_treino);\n",
        "desvio_x_treino = std(x_treino);\n",
        "x_treino = (x_treino .- média_x_treino) ./ desvio_x_treino;\n",
        "y_treino = Flux.onehotbatch(y_treino, 0:9)\n",
        "dados_treino = Flux.Data.DataLoader((x_treino, y_treino), batchsize=128)"
      ],
      "metadata": {
        "id": "3lhuTZyaCx1S",
        "outputId": "13ca3d2a-f909-4ff7-c261-cdb62d88ff3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "391-element DataLoader(::Tuple{CuArray{Float32, 4, CUDA.Mem.DeviceBuffer}, OneHotArrays.OneHotMatrix{UInt32, CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}}}, batchsize=128)\n",
              "  with first element:\n",
              "  (32×32×3×128 CuArray{Float32, 4, CUDA.Mem.DeviceBuffer}, 10×128 OneHotMatrix(::CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}) with eltype Bool,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Teste"
      ],
      "metadata": {
        "id": "YTM2Vgw1C_nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_teste, y_teste = MLDatasets.CIFAR10(Float32, split=:test)[:] |> gpu\n",
        "#x_teste = permutedims(x_teste, (2, 1, 3, 4));\n",
        "#x_teste = convert(CuArray{Float32,4}, x_teste);\n",
        "#x_teste = reshape(x_teste, (32, 32, 3, 10000));\n",
        "média_x_teste = mean(x_teste);\n",
        "desvio_x_teste = std(x_teste);\n",
        "x_teste = (x_teste .- média_x_teste) ./ desvio_x_teste;\n",
        "\n",
        "y_teste = Flux.onehotbatch(y_teste, 0:9)"
      ],
      "metadata": {
        "id": "wAGZzy3lC6ym",
        "outputId": "3e68154e-d8d0-4aa4-ae11-87412b2b1c63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10×10000 OneHotMatrix(::CuArray{UInt32, 1, CUDA.Mem.DeviceBuffer}) with eltype Bool:\n",
              " ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  …  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
              " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  1  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅\n",
              " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
              " 1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  1  ⋅  1  ⋅  1  ⋅  ⋅  ⋅\n",
              " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
              " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  …  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  1  ⋅  ⋅\n",
              " ⋅  ⋅  ⋅  ⋅  1  1  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
              " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1\n",
              " ⋅  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅\n",
              " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação modelo"
      ],
      "metadata": {
        "id": "GhVi9szuC-c_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bekvZY0knj_f"
      },
      "outputs": [],
      "source": [
        "modelo = Chain(\n",
        "    Conv((3, 3), 3 => 64, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    BatchNorm(64),\n",
        "    Conv((3, 3), 64 => 64, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    BatchNorm(64),\n",
        "    MaxPool((2,2)),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Conv((3, 3), 64 => 128, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    BatchNorm(128),\n",
        "    Conv((3, 3), 128 => 128, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    BatchNorm(128),\n",
        "    MaxPool((2,2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv((3, 3), 128 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    BatchNorm(256),\n",
        "    Conv((3, 3), 256 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    BatchNorm(256),\n",
        "    Conv((3, 3), 256 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    BatchNorm(256),\n",
        "    Conv((3, 3), 256 => 256, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    MaxPool((2,2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv((3, 3), 256 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    BatchNorm(512),\n",
        "    Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    BatchNorm(512),\n",
        "    Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    BatchNorm(512),\n",
        "    Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    MaxPool((2,2)),\n",
        "    Dropout(0.35),\n",
        "\n",
        "    Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    BatchNorm(512),\n",
        "    Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    BatchNorm(512),\n",
        "    Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    BatchNorm(512),\n",
        "    Conv((3, 3), 512 => 512, relu, pad=(1, 1), stride=(1, 1)),\n",
        "    MaxPool((2,2)),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    x -> reshape(x, :, size(x, 4)),\n",
        "    Dense(512, 4096, relu),\n",
        "    Dense(4096, 4096, relu),\n",
        "    Dropout(0.5),\n",
        "    Dense(4096, 10),\n",
        "    softmax) |> gpu\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BSON.@load joinpath(\"./\", \"cifar10_conv.bson\") params época acu\n",
        "# Flux.loadparams!(modelo, params)\n",
        "\n",
        "acuracia(ŷ, y) = (mean(Flux.onecold(ŷ) .== Flux.onecold(y)))\n",
        "perda(x, y) = Flux.crossentropy(modelo(x), y)\n",
        "\n",
        "opt = Flux.Optimise.Optimiser(Flux.ADAM(0.001), WeightDecay(0.001))\n",
        "ps = Flux.params(modelo)\n",
        "\n",
        "num_épocas = 25\n",
        "melhor_acu = 0\n",
        "última_melhoria = 0\n",
        "\n",
        "for época in 1:num_épocas\n",
        "   println(\"Época \", época)\n",
        "   Flux.train!(perda, ps, dados_treino, opt)\n",
        "\n",
        "   ŷteste = modelo(x_teste)\n",
        "   acu = acuracia(ŷteste, y_teste)\n",
        "\n",
        "   @info(@sprintf(\"[%d]: Acurácia nos testes: %.4f\", época, acu))\n",
        "\n",
        "   if acu >= melhor_acu\n",
        "      @info(\" -> Uma nova melhor acurácia! Salvando o modelo para cifar10_conv_vgg19.bson\")\n",
        "      BSON.@save joinpath(\"./\", \"cifar10_conv_vgg19.bson\") params = ps época acu\n",
        "      global melhor_acu = acu\n",
        "      global última_melhoria = época\n",
        "   end\n",
        "   # Se a acurácia for muito boa, termine o treino\n",
        "   if acu >= 0.999\n",
        "      @info(\" -> Término prematuro: alcançamos uma acurácia de 99.9%\")\n",
        "      break\n",
        "   end\n",
        "\n",
        "   # Se não houve melhoria em 5 épocas, reduza a taxa de aprendizagem:\n",
        "   if época - última_melhoria >= 5 && opt.eta > 1e-6\n",
        "      opt.eta /= 10.0\n",
        "      @warn(\" -> Sem melhoria por enquanto, reduzindo a taxa de aprendizagem para $(opt.eta)!\")\n",
        "\n",
        "      # Após reduzir a taxa de aprendizagem, dê a ela umas poucas épocas para melhorar\n",
        "      última_melhoria = época\n",
        "   end\n",
        "\n",
        "   if época - última_melhoria >= 10\n",
        "      @warn(\" -> Consideramos que houve convergência.\")\n",
        "      break\n",
        "   end\n",
        "\n",
        "\n",
        "end"
      ],
      "metadata": {
        "id": "sFzSPbn8DIeF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "julia 1.9.1",
      "name": "julia"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}